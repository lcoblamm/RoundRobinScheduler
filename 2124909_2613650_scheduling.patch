diff -Naur orig/linux-2.6.32.60//arch/x86/include/asm/unistd_32.h dev/RoundRobinScheduler/linux-2.6.32.60//arch/x86/include/asm/unistd_32.h
--- orig/linux-2.6.32.60//arch/x86/include/asm/unistd_32.h	2013-03-21 00:34:57.000000000 -0500
+++ dev/RoundRobinScheduler/linux-2.6.32.60//arch/x86/include/asm/unistd_32.h	2015-04-23 23:01:36.000000000 -0500
@@ -343,10 +343,11 @@
 #define __NR_rt_tgsigqueueinfo	335
 #define __NR_perf_event_open	336
 #define __NR_sched_other_rr_getquantum	337
+#define __NR_sched_other_rr_setquantum	338
 
 #ifdef __KERNEL__
 
-#define NR_syscalls 338
+#define NR_syscalls 339
 
 #define __ARCH_WANT_IPC_PARSE_VERSION
 #define __ARCH_WANT_OLD_READDIR
diff -Naur orig/linux-2.6.32.60//arch/x86/kernel/syscall_table_32.S dev/RoundRobinScheduler/linux-2.6.32.60//arch/x86/kernel/syscall_table_32.S
--- orig/linux-2.6.32.60//arch/x86/kernel/syscall_table_32.S	2013-03-21 00:34:57.000000000 -0500
+++ dev/RoundRobinScheduler/linux-2.6.32.60//arch/x86/kernel/syscall_table_32.S	2015-04-22 22:40:30.000000000 -0500
@@ -337,3 +337,4 @@
 	.long sys_rt_tgsigqueueinfo	/* 335 */
 	.long sys_perf_event_open
 	.long sys_sched_other_rr_getquantum
+	.long sys_sched_other_rr_setquantum
diff -Naur orig/linux-2.6.32.60//include/linux/syscalls.h dev/RoundRobinScheduler/linux-2.6.32.60//include/linux/syscalls.h
--- orig/linux-2.6.32.60//include/linux/syscalls.h	2013-03-21 16:29:12.000000000 -0500
+++ dev/RoundRobinScheduler/linux-2.6.32.60//include/linux/syscalls.h	2015-04-22 22:40:35.000000000 -0500
@@ -887,4 +887,6 @@
 			unsigned long fd, unsigned long pgoff);
 
 asmlinkage long sys_sched_other_rr_getquantum(void);
+
+asmlinkage long sys_sched_other_rr_setquantum(unsigned int quantum);
 #endif
diff -Naur orig/linux-2.6.32.60//kernel/sched.c dev/RoundRobinScheduler/linux-2.6.32.60//kernel/sched.c
--- orig/linux-2.6.32.60//kernel/sched.c	2013-03-21 17:33:12.000000000 -0500
+++ dev/RoundRobinScheduler/linux-2.6.32.60//kernel/sched.c	2015-04-24 19:21:04.000000000 -0500
@@ -5541,7 +5541,6 @@
 	int cpu = smp_processor_id();
 	struct rq *rq = cpu_rq(cpu);
 	struct task_struct *curr = rq->curr;
-
 	sched_clock_tick();
 
 	spin_lock(&rq->lock);
@@ -6504,6 +6503,10 @@
 	case SCHED_RR:
 		p->sched_class = &rt_sched_class;
 		break;
+	case SCHED_OTHER_RR:
+		p->sched_class = &other_rr_sched_class;
+		printk(KERN_INFO "Scheduler changed to Other Round Robin\n"); 
+		break;
 	}
 
 	p->rt_priority = prio;
@@ -6552,7 +6555,7 @@
 
 		if (policy != SCHED_FIFO && policy != SCHED_RR &&
 		policy != SCHED_NORMAL && policy != SCHED_BATCH &&
-		policy != SCHED_IDLE)
+		policy != SCHED_IDLE && policy != SCHED_OTHER_RR)
 			return -EINVAL;
 	}
 
@@ -7204,6 +7207,13 @@
 	return retval;
 }
 
+
+SYSCALL_DEFINE1(sched_other_rr_setquantum, unsigned int, quantum){
+    int old_quantum = other_rr_time_slice;
+    other_rr_time_slice = quantum;
+    printk(KERN_INFO "Quantum set to %d\n", other_rr_time_slice);
+    return old_quantum;
+}
 /**
  * sys_sched_getrrquantum - return the default timeslice for the other round
  * robin scheduler.
diff -Naur orig/linux-2.6.32.60//kernel/sched_other_rr.c dev/RoundRobinScheduler/linux-2.6.32.60//kernel/sched_other_rr.c
--- orig/linux-2.6.32.60//kernel/sched_other_rr.c	2013-03-21 16:29:12.000000000 -0500
+++ dev/RoundRobinScheduler/linux-2.6.32.60//kernel/sched_other_rr.c	2015-04-24 21:05:07.000000000 -0500
@@ -31,7 +31,10 @@
  */
 static void enqueue_task_other_rr(struct rq *rq, struct task_struct *p, int wakeup, bool b)
 {
-	// not yet implemented
+	// add task to end of queue
+	list_add_tail(&p->other_rr_run_list, &rq->other_rr.queue);
+	// increment number of tasks in running queue
+	rq->other_rr.nr_running++;
 }
 
 static void dequeue_task_other_rr(struct rq *rq, struct task_struct *p, int sleep)
@@ -39,7 +42,10 @@
 	// first update the task's runtime statistics
 	update_curr_other_rr(rq);
 
-	// not yet implemented
+	// remove task from queue
+	list_del(&p->other_rr_run_list);
+	// update number of tasks in queue
+	rq->other_rr.nr_running--;
 }
 
 /*
@@ -54,10 +60,19 @@
 /*
  * current process is relinquishing control of the CPU
  */
-static void
-yield_task_other_rr(struct rq *rq)
+static void yield_task_other_rr(struct rq *rq)
 {
-	// not yet implemented
+	// if only one in queue, no need to move queue around
+	if (rq->other_rr.nr_running == 1) {
+		return;
+	}
+	// get current task
+	struct task_struct* curr;
+	curr = rq->curr;
+	// reset its time slice to default
+	curr->task_time_slice = other_rr_time_slice;
+	// move to end 
+	requeue_task_other_rr(rq, rq->curr);
 }
 
 /*
@@ -74,19 +89,20 @@
 static struct task_struct *pick_next_task_other_rr(struct rq *rq)
 {
 	struct task_struct *next;
-	struct list_head *queue;
-	struct other_rr_rq *other_rr_rq;
+	struct list_head *queue = &rq->other_rr.queue;
+	struct other_rr_rq *other_rr_rq = &rq->other_rr;
 
-	// not yet implemented
+	if (other_rr_rq->nr_running == 0) {
+		return NULL;
+	}
+
+	next = list_first_entry(queue, struct task_struct, other_rr_run_list);
+
+	// set timer to maintain correct runtime statistics
+	next->se.exec_start = rq->clock;
 
-	/* after selecting a task, we need to set a timer to maintain correct
-	 * runtime statistics. You can uncomment this line after you have
-	 * written the code to select the appropriate task.
-	 */
-	//next->se.exec_start = rq->clock;
-	
 	/* you need to return the selected task here */
-	return NULL;
+	return next;
 }
 
 static void put_prev_task_other_rr(struct rq *rq, struct task_struct *p)
@@ -174,12 +190,25 @@
 /*
  * task_tick_other_rr is invoked on each scheduler timer tick.
  */
-static void task_tick_other_rr(struct rq *rq, struct task_struct *p,int queued)
+static void task_tick_other_rr(struct rq *rq, struct task_struct *p, int queued)
 {
 	// first update the task's runtime statistics
 	update_curr_other_rr(rq);
 
-	// not yet implemented
+	// check if it's FIFO or RR
+	if (other_rr_time_slice == 0) {
+		return;
+	}
+
+	// decrement time by 1
+	if (p->task_time_slice > 0) {
+		p->task_time_slice--;
+		return;
+	}
+	// once it hits 0, reset time, move to end of queue, and set flag to reschedule
+	p->task_time_slice = other_rr_time_slice;
+	set_tsk_need_resched(p);
+	requeue_task_other_rr(rq, p);
 }
 
 /*
